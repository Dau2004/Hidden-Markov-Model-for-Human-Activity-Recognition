{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction for HMM Activity Recognition\n",
    "## Step 2: Extract Time-Domain and Frequency-Domain Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.fft import fft\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all activity data\n",
    "jumping = pd.read_csv('Jumping_all.csv')\n",
    "standing = pd.read_csv('Standing_all.csv')\n",
    "still = pd.read_csv('Still_all.csv')\n",
    "walking = pd.read_csv('Walking_all.csv')\n",
    "\n",
    "# Combine all data\n",
    "data = pd.concat([jumping, standing, still, walking], ignore_index=True)\n",
    "print(f\"Total samples: {len(data)}\")\n",
    "print(f\"\\nActivity distribution:\\n{data['activity'].value_counts()}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(window):\n",
    "    \"\"\"Extract time-domain and frequency-domain features from a window of sensor data\"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Sensor columns\n",
    "    acc_cols = ['acc_x', 'acc_y', 'acc_z']\n",
    "    gyro_cols = ['gyro_x', 'gyro_y', 'gyro_z']\n",
    "    \n",
    "    # TIME-DOMAIN FEATURES\n",
    "    for col in acc_cols + gyro_cols:\n",
    "        signal = window[col].values\n",
    "        features[f'{col}_mean'] = np.mean(signal)\n",
    "        features[f'{col}_std'] = np.std(signal)\n",
    "        features[f'{col}_var'] = np.var(signal)\n",
    "        features[f'{col}_min'] = np.min(signal)\n",
    "        features[f'{col}_max'] = np.max(signal)\n",
    "        features[f'{col}_range'] = np.max(signal) - np.min(signal)\n",
    "    \n",
    "    # Signal Magnitude Area (SMA)\n",
    "    features['acc_sma'] = np.sum(np.abs(window[acc_cols].values)) / len(window)\n",
    "    features['gyro_sma'] = np.sum(np.abs(window[gyro_cols].values)) / len(window)\n",
    "    \n",
    "    # Correlation between axes\n",
    "    features['acc_xy_corr'] = np.corrcoef(window['acc_x'], window['acc_y'])[0, 1]\n",
    "    features['acc_xz_corr'] = np.corrcoef(window['acc_x'], window['acc_z'])[0, 1]\n",
    "    features['acc_yz_corr'] = np.corrcoef(window['acc_y'], window['acc_z'])[0, 1]\n",
    "    features['gyro_xy_corr'] = np.corrcoef(window['gyro_x'], window['gyro_y'])[0, 1]\n",
    "    features['gyro_xz_corr'] = np.corrcoef(window['gyro_x'], window['gyro_z'])[0, 1]\n",
    "    features['gyro_yz_corr'] = np.corrcoef(window['gyro_y'], window['gyro_z'])[0, 1]\n",
    "    \n",
    "    # FREQUENCY-DOMAIN FEATURES\n",
    "    for col in acc_cols + gyro_cols:\n",
    "        signal = window[col].values\n",
    "        fft_vals = np.abs(fft(signal))\n",
    "        fft_vals = fft_vals[:len(fft_vals)//2]  # Take positive frequencies\n",
    "        \n",
    "        features[f'{col}_spectral_energy'] = np.sum(fft_vals**2)\n",
    "        features[f'{col}_dominant_freq_idx'] = np.argmax(fft_vals)\n",
    "        features[f'{col}_spectral_entropy'] = stats.entropy(fft_vals + 1e-10)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Feature Extraction with Sliding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Window parameters\n",
    "WINDOW_SIZE = 50  # Number of samples per window\n",
    "OVERLAP = 25      # Overlap between windows\n",
    "\n",
    "feature_list = []\n",
    "\n",
    "# Process each session separately\n",
    "for session in data['session'].unique():\n",
    "    session_data = data[data['session'] == session].reset_index(drop=True)\n",
    "    activity = session_data['activity'].iloc[0]\n",
    "    \n",
    "    # Sliding window\n",
    "    for start in range(0, len(session_data) - WINDOW_SIZE + 1, WINDOW_SIZE - OVERLAP):\n",
    "        window = session_data.iloc[start:start + WINDOW_SIZE]\n",
    "        features = extract_features(window)\n",
    "        features['activity'] = activity\n",
    "        features['session'] = session\n",
    "        feature_list.append(features)\n",
    "\n",
    "# Create feature dataframe\n",
    "features_df = pd.DataFrame(feature_list)\n",
    "print(f\"\\nExtracted features shape: {features_df.shape}\")\n",
    "print(f\"\\nFeatures per activity:\\n{features_df['activity'].value_counts()}\")\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Extracted Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.to_csv('extracted_features.csv', index=False)\n",
    "print(\"Features saved to 'extracted_features.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select key features for visualization\n",
    "key_features = ['acc_x_mean', 'acc_y_mean', 'acc_z_mean', 'acc_sma', \n",
    "                'gyro_x_std', 'gyro_y_std', 'gyro_z_std', 'gyro_sma']\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(key_features):\n",
    "    for activity in features_df['activity'].unique():\n",
    "        data_subset = features_df[features_df['activity'] == activity][feature]\n",
    "        axes[idx].hist(data_subset, alpha=0.5, label=activity, bins=20)\n",
    "    axes[idx].set_title(feature)\n",
    "    axes[idx].legend()\n",
    "    axes[idx].set_xlabel('Value')\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_distributions.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary by activity\n",
    "numeric_cols = features_df.select_dtypes(include=[np.number]).columns\n",
    "summary = features_df.groupby('activity')[numeric_cols].mean()\n",
    "print(\"\\nMean features by activity:\")\n",
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
